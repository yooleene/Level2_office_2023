{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "njXpmXifM6D-"
   },
   "source": [
    "## <b>M4.3_키워드 분석(Keyword Analysis)</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pvUu6DwlNLm9"
   },
   "source": [
    "- 키워드란 텍스트 자료의 중요한 내용을 압축적으로 제시하는 단어 또는 문구이다.\n",
    "- 키워드 분석이란 불용어 제거와 어간추출 및 형태소 분석 등을 시행한 후 텍스트에서 많이 등장하는 형태소의 등장 빈도를 분석함으로써 핵심어를 추출하는 것이다.   \n",
    "- 특정 텍스트 자료에 많이 나타나는 형태소가 그 텍스트 주제를 표출할 가능성이 높다는 가정에 기초한다.  \n",
    "- 물론, 빈도 분석에서 영어의 전치사나 한국어의 조사와 같이 의미를 별로 담고 있지 않은 불용어는 제외하는 것이 좋다.\n",
    "- 키워드 분석은 텍스트의 주제 추정, 텍스트 유사도, 검색 엔진의 검색 결과 우선 순위 측정 등 다양하게 사용될 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJWPH28S2Bp"
   },
   "source": [
    "##### ① 데이터셋 파일 읽기\n",
    "- 네이버 영화 리뷰 데이터 https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id\\tdocument\\tlabel\\n', '8112052\\t어릴때보고 지금다시봐도 재밌어요ㅋㅋ\\t1\\n', '8132799\\t디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업이 부러웠는데. 사실 우리나라에서도 그 어려운시절에 끝까지 열정을 지킨 노라노 같은 전통이있어 저와 같은 사람들이 꿈을 꾸고 이뤄나갈 수 있다는 것에 감사합니다.\\t1\\n']\n"
     ]
    }
   ],
   "source": [
    "f = open('data_set/ratings.txt', 'r', encoding='utf-8') \n",
    "raw = f.readlines()\n",
    "print(raw[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ② 리뷰 데이터만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document', '어릴때보고 지금다시봐도 재밌어요ㅋㅋ', '디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업이 부러웠는데. 사실 우리나라에서도 그 어려운시절에 끝까지 열정을 지킨 노라노 같은 전통이있어 저와 같은 사람들이 꿈을 꾸고 이뤄나갈 수 있다는 것에 감사합니다.', '폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.', '와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런게 진짜 영화지']\n"
     ]
    }
   ],
   "source": [
    "reviews = []\n",
    "\n",
    "for i in raw:\n",
    "      reviews.append(i.split('\\t')[1])\n",
    "print(reviews[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'document' 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['어릴때보고 지금다시봐도 재밌어요ㅋㅋ', '디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업이 부러웠는데. 사실 우리나라에서도 그 어려운시절에 끝까지 열정을 지킨 노라노 같은 전통이있어 저와 같은 사람들이 꿈을 꾸고 이뤄나갈 수 있다는 것에 감사합니다.', '폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.', '와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런게 진짜 영화지', '안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.']\n"
     ]
    }
   ],
   "source": [
    "reviews = reviews[1:]\n",
    "print(reviews[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "65sLf2AkL440"
   },
   "source": [
    "### 2. 형태소 분석"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ① 불용어(Stopwords) 제거를 위한 불용어 사전 만들기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 형태소 분석을 통해 조사, 접속사 등의 제거 가능하다.\n",
    "* 하지만 한국어는 명사에서도 상당히 많은 불필요한 단어들이 포함한다.\n",
    "* 사용자가 직접 불용어 사전을 유지하면서 불필요한 단어 제거 필요하다.\n",
    "* 불용어 예: `영화 전 난 일 걸 뭐 줄 만 건 분 개 끝 잼 이거 번 중 듯 때 게 내 말 나 수 거 점 것`\n",
    "* 빈도가 너무 커서 분석에 방해되는 단어도 제거 필요하다.(예: `영화`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PxXHMeHEL446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['영화', '전', '난', '일', '걸', '뭐', '줄', '만', '건', '분', '개', '끝', '잼', '이거', '번', '중', '듯', '때', '게', '내', '말', '나', '수', '거', '점', '것']\n"
     ]
    }
   ],
   "source": [
    "stop_words = '영화 전 난 일 걸 뭐 줄 만 건 분 개 끝 잼 이거 번 중 듯 때 게 내 말 나 수 거 점 것'\n",
    "stop_words = stop_words.split()\n",
    "print(stop_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QHBAWtzAL449"
   },
   "source": [
    "##### ② 불용어를 제외하여 형태소 분석 - 명사만 추출(5분 소요)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 한글 텍스트에 대해서 형태소 분석 수행한다.\n",
    "* 분석으로 추출하는 명사 중에서 불용어에 포함되지 않은 텍스트만 추출하여 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "\n",
    "kiwi = Kiwi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [01:43<00:00, 1939.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['디자인', '학생', '외국', '디자이너', '그', '전통', '발전', '문화', '산업', '우리', '나라', '시절', '열정', '노라노', '전통', '저', '사람', '꿈', '감사', '폴리스', '스토리', '시리즈', '뉴', '하나', '최고', '연기', '개쩔', '생각', '몰입', '진짜', '안개', '밤하늘', '초승달', '사랑', '사람', '처음', '감동', '감동', '전쟁', '빠로', '굿', '바보', '병', '쉰', '나이', '감동', '훗날', '대사', '감정', '완벽', '이해', '고질라', '능', '오페라', '작품', '극단', '평', '도', '반전', '평점', '긴장감', '스릴', '최고', '전장', '공포', '네고시에이터', '소재', '뿐', '관련', '최고', '밀회', '생각', '상당', '수작', '일본', '년', '최고', '마음', '임팩트', '일품', '오랜만', '범죄', '스릴러', '사랑', '마디', '밤', '잠', '커징텅의', '교복', '션자이', '볼펜', '자국', '마음', '형태', '마지막', '씬', '강압', '용서', '세뇌', '적용']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "review_token = []\n",
    "\n",
    "for review in tqdm(reviews):\n",
    "    for token in kiwi.tokenize(review):\n",
    "        if (token.tag[0] == 'N') & (token.form not in stop_words):\n",
    "                review_token.append(token.form)\n",
    "print(review_token[:100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QHRt9alfTMj3"
   },
   "source": [
    "### 3. 빈도 분석"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 단어 빈도수 측정"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MXbsTUQLA7FH"
   },
   "source": [
    "* 단어 빈도수 측정에는 `collections` 패키지의 `Counter` 함수를 이용한다.\n",
    "* `collections` 패키지는 내장 패키지로 별도 설치가 필요 없다.\n",
    "* `counter`를 이용하면 각 단어와 각 단어의 빈도 수를 딕셔너리로 편리하게 생성 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nnOU6NDTWM9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "t6w6mEQ_Aamt"
   },
   "source": [
    "#### 2) 단어 빈도 시각화(그래프)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ① 한글 폰트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDd_QGuRmGe5"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 폰트 매니저에서 관리하는 폰트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([f.name for f in fm.fontManager.ttflist]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ② 세로 막대 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEP8sDZuAbC9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jOvekEYJNBHd"
   },
   "source": [
    "#### 3) 단어 빈도 시각화(워드클라우드; WordCloud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 텍스트에 담겨있는 여러 형태소들의 등장 빈도를 가장 직관적으로 시각화하는 방법이다.\n",
    "* 텍스트에 등장하는 단어를 그 등장 빈도에 따라 서로 크기가 다르게 구름 형태로 표현함으로써, 단어의 빈도 수를 한번에 알 수 있다.\n",
    "* 최근에 많은 서비스들이 어떤 핵심어가 많이 등장했는가를 워드클라우드 형식으로 시각화한다.\n",
    "* 빈도 수만을 시각적으로 표현한 것이기 때문에, 단어들 사이의 연관성이나 의미 구조 등을 분석하는 데는 한계가 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ① 파이썬에서 워드 클라우드를 시각화하기 위해 `matplotlib`와 `WordCloud`를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kARobmm2NDgl"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MHtxdWK5irIr"
   },
   "source": [
    "##### ② WordCloud를 이용해 객체를 생성해주고, `generate_from_frequencies()` 함수로 빈도 수에 따라 워드클라우드 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUYNxKiqOoDz"
   },
   "outputs": [],
   "source": [
    "wc = WordCloud(font_path = 'gulim',  width=800, height=400, scale=2.0, max_font_size=250, max_words=200, background_color='white')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ③ 배경 이미지에 워드클라우드 생성 - 배경 이미지를 배열로 변경하여 그 안에 들어가게 만드는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BEY3ldWmNECt"
   },
   "source": [
    "#### 4) 단어 빈도 시각화(squarify 트리맵)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ApiLK6KhZM3d"
   },
   "source": [
    "* `squarify`는 트리맵 생성을 지원해주는 파이썬 라이브러리이다.\n",
    "* `squarify`를 이용해 키워드와 키워드 빈도 수를 트리맵으로 나타낸다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cj_Y-VslNJDg"
   },
   "outputs": [],
   "source": [
    "import squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = mpl.colors.Normalize(vmin=min(top_c.values()),vmax=max(top_c.values())) \n",
    "\n",
    "colors = [mpl.cm.Blues(norm(value)) for value in top_c.values()] \n",
    "fig, ax = plt.subplots(1, figsize = (10,8)) \n",
    "squarify.plot(label=top_c.keys(), sizes=top_c.values(), color=colors, alpha=0.7);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2782e0ab7cab974e8fb2dfc8cec048a29dc3b50e54743df0c4a34ac41b2be7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
